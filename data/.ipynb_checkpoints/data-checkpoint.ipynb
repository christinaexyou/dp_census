{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ef6179d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import functools\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "638e053c",
   "metadata": {},
   "source": [
    "Workflow:\n",
    "\n",
    "I. Loading 2010 SF1 data from Massachussetts and creating tables based on variables of interest\n",
    "\n",
    "II. Loading 2010 DHC data from Massachussetts and creating tables based on variables of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c21b7358",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking working directory\n",
    "os.getcwd\n",
    "path = '/Users/christinaxu/Documents/dp_census'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de954769",
   "metadata": {},
   "source": [
    "I. Loading 2010 SF1 data from Massachusetts\n",
    "\n",
    "a) Read in the segments of the 2010 SF1 for Massachusetts downloaded from [here](https://archive.ciser.cornell.edu/explore/download-centers/census-2010-sf1/files)\n",
    "\n",
    "b) The specific segments are selected based on the columns from on Abie and Os's work:\n",
    "* P8 - race in 63 categories\n",
    "* P9 - race in 63 categories, non-hispanic\n",
    "* P10 - race in 63 categories for 18+\n",
    "* P11 - race in 63 categories, non-hispanic for 18+\n",
    "* P12 - sex by age\n",
    "* P14 - sex by for below 20 years of age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3112e571",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/christinaxu/opt/anaconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3444: DtypeWarning: Columns (3,28,29,33,34,47,48,49,50,52,53,54,55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "sf1_1 = pd.read_csv(path + '/ma2010ur1_49segments_csv/ma000012010ur1.CSV')\n",
    "sf1_2 = pd.read_csv(path + '/ma2010ur1_49segments_csv/ma000022010ur1.CSV')\n",
    "sf1_3 = pd.read_csv(path + '/ma2010ur1_49segments_csv/ma000032010ur1.CSV')\n",
    "sf1_4 = pd.read_csv(path + '/ma2010ur1_49segments_csv/ma000042010ur1.CSV')\n",
    "sf1_7 = pd.read_csv(path + '/ma2010ur1_49segments_csv/ma000072010ur1.CSV')\n",
    "sf1_8 = pd.read_csv(path + '/ma2010ur1_49segments_csv/ma000082010ur1.CSV')\n",
    "mass_geo = pd.read_csv(path + '/ma2010ur1_49segments_csv/mageo2010ur1.CSV')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "215b995b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FILEID</th>\n",
       "      <th>STUSAB</th>\n",
       "      <th>CHARITER</th>\n",
       "      <th>CIFSN</th>\n",
       "      <th>LOGRECNO</th>\n",
       "      <th>P0010001</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UR1ST</td>\n",
       "      <td>MA</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>6547629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>UR1ST</td>\n",
       "      <td>MA</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>6021989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>UR1ST</td>\n",
       "      <td>MA</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>5912700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>UR1ST</td>\n",
       "      <td>MA</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>109289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UR1ST</td>\n",
       "      <td>MA</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>525640</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  FILEID STUSAB  CHARITER  CIFSN  LOGRECNO  P0010001\n",
       "0  UR1ST     MA         0    NaN         1   6547629\n",
       "1  UR1ST     MA         0    NaN         2   6021989\n",
       "2  UR1ST     MA         0    NaN         3   5912700\n",
       "3  UR1ST     MA         0    NaN         4    109289\n",
       "4  UR1ST     MA         0    NaN         5    525640"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sf1_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06561788",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FILEID</th>\n",
       "      <th>STUSAB</th>\n",
       "      <th>CHARITER</th>\n",
       "      <th>CIFSN</th>\n",
       "      <th>LOGRECNO</th>\n",
       "      <th>P0020001</th>\n",
       "      <th>P0020002</th>\n",
       "      <th>P0020003</th>\n",
       "      <th>P0020004</th>\n",
       "      <th>P0020005</th>\n",
       "      <th>P0020006</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UR1ST</td>\n",
       "      <td>MA</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>6547629</td>\n",
       "      <td>6021989</td>\n",
       "      <td>5912700</td>\n",
       "      <td>109289</td>\n",
       "      <td>525640</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>UR1ST</td>\n",
       "      <td>MA</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>6021989</td>\n",
       "      <td>6021989</td>\n",
       "      <td>5912700</td>\n",
       "      <td>109289</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>UR1ST</td>\n",
       "      <td>MA</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>5912700</td>\n",
       "      <td>5912700</td>\n",
       "      <td>5912700</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>UR1ST</td>\n",
       "      <td>MA</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>109289</td>\n",
       "      <td>109289</td>\n",
       "      <td>0</td>\n",
       "      <td>109289</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UR1ST</td>\n",
       "      <td>MA</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>525640</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>525640</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  FILEID STUSAB  CHARITER  CIFSN  LOGRECNO  P0020001  P0020002  P0020003  \\\n",
       "0  UR1ST     MA         0    NaN         1   6547629   6021989   5912700   \n",
       "1  UR1ST     MA         0    NaN         2   6021989   6021989   5912700   \n",
       "2  UR1ST     MA         0    NaN         3   5912700   5912700   5912700   \n",
       "3  UR1ST     MA         0    NaN         4    109289    109289         0   \n",
       "4  UR1ST     MA         0    NaN         5    525640         0         0   \n",
       "\n",
       "   P0020004  P0020005  P0020006  \n",
       "0    109289    525640         0  \n",
       "1    109289         0         0  \n",
       "2         0         0         0  \n",
       "3    109289         0         0  \n",
       "4         0    525640         0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sf1_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "15891f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "mass_geo.head()\n",
    "mass_geo = mass_geo[['FILEID', 'STUSAB', 'CHARITER', 'CIFSN', 'LOGRECNO', 'BLOCK', 'COUNTY', 'TRACT']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d1e59ac",
   "metadata": {},
   "source": [
    "c) Rather than dealing with 4 tables, let's merge them into a larger table based on LOGRECNO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb0d3954",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_list = [sf1_1, sf1_2, sf1_3, sf1_4, sf1_7, sf1_8, mass_geo]\n",
    "sf1_mass = functools.reduce(lambda x, y: pd.merge(x,y, on=sf1_1.columns[:5].to_list()), table_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad09b048",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FILEID</th>\n",
       "      <th>STUSAB</th>\n",
       "      <th>CHARITER</th>\n",
       "      <th>CIFSN</th>\n",
       "      <th>LOGRECNO</th>\n",
       "      <th>P0010001</th>\n",
       "      <th>P0020001</th>\n",
       "      <th>P0020002</th>\n",
       "      <th>P0020003</th>\n",
       "      <th>P0020004</th>\n",
       "      <th>...</th>\n",
       "      <th>P016H003</th>\n",
       "      <th>P016I001</th>\n",
       "      <th>P016I002</th>\n",
       "      <th>P016I003</th>\n",
       "      <th>P017A001</th>\n",
       "      <th>P017A002</th>\n",
       "      <th>P017A003</th>\n",
       "      <th>BLOCK</th>\n",
       "      <th>COUNTY</th>\n",
       "      <th>TRACT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UR1ST</td>\n",
       "      <td>MA</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>6547629</td>\n",
       "      <td>6547629</td>\n",
       "      <td>6021989</td>\n",
       "      <td>5912700</td>\n",
       "      <td>109289</td>\n",
       "      <td>...</td>\n",
       "      <td>385633</td>\n",
       "      <td>4892298</td>\n",
       "      <td>1003956</td>\n",
       "      <td>3888342</td>\n",
       "      <td>2.40</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.89</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>UR1ST</td>\n",
       "      <td>MA</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>6021989</td>\n",
       "      <td>6021989</td>\n",
       "      <td>6021989</td>\n",
       "      <td>5912700</td>\n",
       "      <td>109289</td>\n",
       "      <td>...</td>\n",
       "      <td>381060</td>\n",
       "      <td>4394984</td>\n",
       "      <td>891147</td>\n",
       "      <td>3503837</td>\n",
       "      <td>2.38</td>\n",
       "      <td>0.49</td>\n",
       "      <td>1.88</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>UR1ST</td>\n",
       "      <td>MA</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>5912700</td>\n",
       "      <td>5912700</td>\n",
       "      <td>5912700</td>\n",
       "      <td>5912700</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>378278</td>\n",
       "      <td>4300601</td>\n",
       "      <td>872634</td>\n",
       "      <td>3427967</td>\n",
       "      <td>2.38</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.88</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>UR1ST</td>\n",
       "      <td>MA</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>109289</td>\n",
       "      <td>109289</td>\n",
       "      <td>109289</td>\n",
       "      <td>0</td>\n",
       "      <td>109289</td>\n",
       "      <td>...</td>\n",
       "      <td>2782</td>\n",
       "      <td>94383</td>\n",
       "      <td>18513</td>\n",
       "      <td>75870</td>\n",
       "      <td>2.20</td>\n",
       "      <td>0.44</td>\n",
       "      <td>1.76</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UR1ST</td>\n",
       "      <td>MA</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>525640</td>\n",
       "      <td>525640</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4573</td>\n",
       "      <td>497314</td>\n",
       "      <td>112809</td>\n",
       "      <td>384505</td>\n",
       "      <td>2.62</td>\n",
       "      <td>0.60</td>\n",
       "      <td>2.02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 952 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  FILEID STUSAB  CHARITER  CIFSN  LOGRECNO  P0010001  P0020001  P0020002  \\\n",
       "0  UR1ST     MA         0    NaN         1   6547629   6547629   6021989   \n",
       "1  UR1ST     MA         0    NaN         2   6021989   6021989   6021989   \n",
       "2  UR1ST     MA         0    NaN         3   5912700   5912700   5912700   \n",
       "3  UR1ST     MA         0    NaN         4    109289    109289    109289   \n",
       "4  UR1ST     MA         0    NaN         5    525640    525640         0   \n",
       "\n",
       "   P0020003  P0020004  ...  P016H003  P016I001  P016I002  P016I003  P017A001  \\\n",
       "0   5912700    109289  ...    385633   4892298   1003956   3888342      2.40   \n",
       "1   5912700    109289  ...    381060   4394984    891147   3503837      2.38   \n",
       "2   5912700         0  ...    378278   4300601    872634   3427967      2.38   \n",
       "3         0    109289  ...      2782     94383     18513     75870      2.20   \n",
       "4         0         0  ...      4573    497314    112809    384505      2.62   \n",
       "\n",
       "   P017A002  P017A003  BLOCK  COUNTY  TRACT  \n",
       "0      0.50      1.89    NaN     NaN    NaN  \n",
       "1      0.49      1.88    NaN     NaN    NaN  \n",
       "2      0.50      1.88    NaN     NaN    NaN  \n",
       "3      0.44      1.76    NaN     NaN    NaN  \n",
       "4      0.60      2.02    NaN     NaN    NaN  \n",
       "\n",
       "[5 rows x 952 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sf1_mass.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b8d5920",
   "metadata": {},
   "source": [
    "d) Dropping column CIFSN and any rows that contain NaN values and columns P013+ since they aren't included in the model. In addition, renaming STUSAB to state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "48ec219c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FILEID           0\n",
       "STUSAB           0\n",
       "CHARITER         0\n",
       "CIFSN       196412\n",
       "LOGRECNO         0\n",
       "             ...  \n",
       "P017A002         0\n",
       "P017A003         0\n",
       "BLOCK        38904\n",
       "COUNTY        3130\n",
       "TRACT         9439\n",
       "Length: 952, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sf1_mass.isna().sum() # CIFSN is the only column with all na values so drop it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ce6184a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop = ['CIFSN'] + list(sf1_mass.filter(regex='P013|P015|P016|P017'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c8a12020",
   "metadata": {},
   "outputs": [],
   "source": [
    "sf1_mass.drop(cols_to_drop, axis=1, inplace=True)\n",
    "sf1_mass.dropna(inplace=True)\n",
    "sf1_mass.rename(columns={'STUSAB':'STATE'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2f2fc4f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FILEID</th>\n",
       "      <th>STATE</th>\n",
       "      <th>CHARITER</th>\n",
       "      <th>LOGRECNO</th>\n",
       "      <th>P0010001</th>\n",
       "      <th>P0020001</th>\n",
       "      <th>P0020002</th>\n",
       "      <th>P0020003</th>\n",
       "      <th>P0020004</th>\n",
       "      <th>P0020005</th>\n",
       "      <th>...</th>\n",
       "      <th>P012I043</th>\n",
       "      <th>P012I044</th>\n",
       "      <th>P012I045</th>\n",
       "      <th>P012I046</th>\n",
       "      <th>P012I047</th>\n",
       "      <th>P012I048</th>\n",
       "      <th>P012I049</th>\n",
       "      <th>BLOCK</th>\n",
       "      <th>COUNTY</th>\n",
       "      <th>TRACT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>UR1ST</td>\n",
       "      <td>MA</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10206.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>UR1ST</td>\n",
       "      <td>MA</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3163.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10206.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>UR1ST</td>\n",
       "      <td>MA</td>\n",
       "      <td>0</td>\n",
       "      <td>66</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10208.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>UR1ST</td>\n",
       "      <td>MA</td>\n",
       "      <td>0</td>\n",
       "      <td>67</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3001.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10208.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>UR1ST</td>\n",
       "      <td>MA</td>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1019.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10400.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 891 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   FILEID STATE  CHARITER  LOGRECNO  P0010001  P0020001  P0020002  P0020003  \\\n",
       "59  UR1ST    MA         0        60         0         0         0         0   \n",
       "60  UR1ST    MA         0        61         0         0         0         0   \n",
       "65  UR1ST    MA         0        66         0         0         0         0   \n",
       "66  UR1ST    MA         0        67         0         0         0         0   \n",
       "71  UR1ST    MA         0        72         0         0         0         0   \n",
       "\n",
       "    P0020004  P0020005  ...  P012I043  P012I044  P012I045  P012I046  P012I047  \\\n",
       "59         0         0  ...         0         0         0         0         0   \n",
       "60         0         0  ...         0         0         0         0         0   \n",
       "65         0         0  ...         0         0         0         0         0   \n",
       "66         0         0  ...         0         0         0         0         0   \n",
       "71         0         0  ...         0         0         0         0         0   \n",
       "\n",
       "    P012I048  P012I049   BLOCK  COUNTY    TRACT  \n",
       "59         0         0  3000.0     1.0  10206.0  \n",
       "60         0         0  3163.0     1.0  10206.0  \n",
       "65         0         0  3000.0     1.0  10208.0  \n",
       "66         0         0  3001.0     1.0  10208.0  \n",
       "71         0         0  1019.0     1.0  10400.0  \n",
       "\n",
       "[5 rows x 891 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sf1_mass.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "68cf88b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1838\n",
      "14\n",
      "1469\n"
     ]
    }
   ],
   "source": [
    "print(sf1_mass['BLOCK'].nunique())\n",
    "print(sf1_mass['COUNTY'].nunique())\n",
    "print(sf1_mass['TRACT'].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "035b1e15",
   "metadata": {},
   "source": [
    "e) Dividing sf1_mass into smaller dfs based on variables of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "19afdc7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['STATE', 'LOGRECNO', 'BLOCK', 'COUNTY', 'TRACT']\n",
    "\n",
    "P1 = sf1_mass[cols + list(sf1_mass.filter(regex='P001'))] # Total pop\n",
    "P8 = sf1_mass[cols + list(sf1_mass.filter(regex='P008'))] # Race\n",
    "P9 = sf1_mass[cols + list(sf1_mass.filter(regex='P009'))] # Hispanic or Latino\n",
    "P10 = sf1_mass[cols + list(sf1_mass.filter(regex='P010'))] # Race for 18+\n",
    "P11 = sf1_mass[cols + list(sf1_mass.filter(regex='P011'))] # Hispanic or Latio for 18+\n",
    "P12 = sf1_mass[cols + list(sf1_mass.filter(regex='P012'))] # Sex by age\n",
    "P14 = sf1_mass[cols + list(sf1_mass.filter(regex='P014'))] # Sex by age for under 20 years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e2646fff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATE</th>\n",
       "      <th>LOGRECNO</th>\n",
       "      <th>BLOCK</th>\n",
       "      <th>COUNTY</th>\n",
       "      <th>TRACT</th>\n",
       "      <th>P0120001</th>\n",
       "      <th>P0120002</th>\n",
       "      <th>P0120003</th>\n",
       "      <th>P0120004</th>\n",
       "      <th>P0120005</th>\n",
       "      <th>...</th>\n",
       "      <th>P012I040</th>\n",
       "      <th>P012I041</th>\n",
       "      <th>P012I042</th>\n",
       "      <th>P012I043</th>\n",
       "      <th>P012I044</th>\n",
       "      <th>P012I045</th>\n",
       "      <th>P012I046</th>\n",
       "      <th>P012I047</th>\n",
       "      <th>P012I048</th>\n",
       "      <th>P012I049</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>MA</td>\n",
       "      <td>60</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10206.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>MA</td>\n",
       "      <td>61</td>\n",
       "      <td>3163.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10206.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>MA</td>\n",
       "      <td>66</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10208.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>MA</td>\n",
       "      <td>67</td>\n",
       "      <td>3001.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10208.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>MA</td>\n",
       "      <td>72</td>\n",
       "      <td>1019.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10400.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 495 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   STATE  LOGRECNO   BLOCK  COUNTY    TRACT  P0120001  P0120002  P0120003  \\\n",
       "59    MA        60  3000.0     1.0  10206.0         0         0         0   \n",
       "60    MA        61  3163.0     1.0  10206.0         0         0         0   \n",
       "65    MA        66  3000.0     1.0  10208.0         0         0         0   \n",
       "66    MA        67  3001.0     1.0  10208.0         0         0         0   \n",
       "71    MA        72  1019.0     1.0  10400.0         0         0         0   \n",
       "\n",
       "    P0120004  P0120005  ...  P012I040  P012I041  P012I042  P012I043  P012I044  \\\n",
       "59         0         0  ...         0         0         0         0         0   \n",
       "60         0         0  ...         0         0         0         0         0   \n",
       "65         0         0  ...         0         0         0         0         0   \n",
       "66         0         0  ...         0         0         0         0         0   \n",
       "71         0         0  ...         0         0         0         0         0   \n",
       "\n",
       "    P012I045  P012I046  P012I047  P012I048  P012I049  \n",
       "59         0         0         0         0         0  \n",
       "60         0         0         0         0         0  \n",
       "65         0         0         0         0         0  \n",
       "66         0         0         0         0         0  \n",
       "71         0         0         0         0         0  \n",
       "\n",
       "[5 rows x 495 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P12.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1adea55b",
   "metadata": {},
   "source": [
    "f) Futher dividing P12 into smaller dfs based on race categories which can be found [here](https://api.census.gov/data/2010/dec/sf1/variables.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "00304039",
   "metadata": {},
   "outputs": [],
   "source": [
    "letters = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I']\n",
    "df_list_filtered = []\n",
    "\n",
    "for letter in letters:\n",
    "    df = P12[cols + list(sf1_mass.filter(regex= f'P012{letter}'))]\n",
    "    df_list_filtered.append(df)\n",
    "    \n",
    "P12A = df_list_filtered[0] # sex by age (White)\n",
    "P12B = df_list_filtered[1] # sex by age (Black or African American)\n",
    "P12C = df_list_filtered[2] # sex by age (Native American or Alaska Native)\n",
    "P12D = df_list_filtered[3] # ... (Asian)\n",
    "P12E = df_list_filtered[4] # ... (Native Hawaiian and other Pacific Islander)\n",
    "P12F = df_list_filtered[5] # ... (\"Some other Race\")\n",
    "P12G = df_list_filtered[6] # ... (2 or more races)                    \n",
    "P12H = df_list_filtered[7] # ... (Hispanic or Latino)\n",
    "P12I = df_list_filtered[8] # .... (None Hispanic or Latino White)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "69b4dad1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/christinaxu/opt/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py:4906: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['P0120001',\n",
       " 'P0120002',\n",
       " 'P0120003',\n",
       " 'P0120004',\n",
       " 'P0120005',\n",
       " 'P0120006',\n",
       " 'P0120007',\n",
       " 'P0120008',\n",
       " 'P0120009',\n",
       " 'P0120010',\n",
       " 'P0120011',\n",
       " 'P0120012',\n",
       " 'P0120013',\n",
       " 'P0120014',\n",
       " 'P0120015',\n",
       " 'P0120016',\n",
       " 'P0120017',\n",
       " 'P0120018',\n",
       " 'P0120019',\n",
       " 'P0120020',\n",
       " 'P0120021',\n",
       " 'P0120022',\n",
       " 'P0120023',\n",
       " 'P0120024',\n",
       " 'P0120025',\n",
       " 'P0120026',\n",
       " 'P0120027',\n",
       " 'P0120028',\n",
       " 'P0120029',\n",
       " 'P0120030',\n",
       " 'P0120031',\n",
       " 'P0120032',\n",
       " 'P0120033',\n",
       " 'P0120034',\n",
       " 'P0120035',\n",
       " 'P0120036',\n",
       " 'P0120037',\n",
       " 'P0120038',\n",
       " 'P0120039',\n",
       " 'P0120040',\n",
       " 'P0120041',\n",
       " 'P0120042',\n",
       " 'P0120043',\n",
       " 'P0120044',\n",
       " 'P0120045',\n",
       " 'P0120046',\n",
       " 'P0120047',\n",
       " 'P0120048',\n",
       " 'P0120049']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dropping the above variables from P12 \n",
    "P12.drop(list(P12.filter(regex='A|B|C|D|E|F|G|H|I')), axis=1, inplace=True)\n",
    "P12.columns.to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c73bcd",
   "metadata": {},
   "source": [
    "g) Saving dfs to csv files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bccfae09",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/christinaxu/Documents/dp_census/mass_sf1/table_P1.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/yq/w1r3w66n7qv1d9j6x_jp9k9r0000gn/T/ipykernel_7123/496069144.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mname_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'P1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'P8'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'P9'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'P10'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'P11'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'P12'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'P12A'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'P12B'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'P12C'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'P12D'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'P12E'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'P12F'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'P12G'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'P12H'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'P12I'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'P14'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtable_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mname_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mtable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/mass_sf1/table_{}.csv'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mto_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[1;32m   3464\u001b[0m         )\n\u001b[1;32m   3465\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3466\u001b[0;31m         return DataFrameRenderer(formatter).to_csv(\n\u001b[0m\u001b[1;32m   3467\u001b[0m             \u001b[0mpath_or_buf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3468\u001b[0m             \u001b[0mline_terminator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mline_terminator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/formats/format.py\u001b[0m in \u001b[0;36mto_csv\u001b[0;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[1;32m   1103\u001b[0m             \u001b[0mformatter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfmt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         )\n\u001b[0;32m-> 1105\u001b[0;31m         \u001b[0mcsv_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1107\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcreated_buffer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/formats/csvs.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    235\u001b[0m         \"\"\"\n\u001b[1;32m    236\u001b[0m         \u001b[0;31m# apply compression and byte/text conversion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m         with get_handle(\n\u001b[0m\u001b[1;32m    238\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    700\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    703\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/christinaxu/Documents/dp_census/mass_sf1/table_P1.csv'"
     ]
    }
   ],
   "source": [
    "table_list = [P1, P8, P9, P10, P11, P12, P12A, P12B, P12C, P12D, P12E, P12F, P12G, P12H, P12I, P14]\n",
    "name_list = ['P1', 'P8', 'P9', 'P10', 'P11', 'P12', 'P12A', 'P12B', 'P12C', 'P12D', 'P12E', 'P12F', 'P12G', 'P12H', 'P12I', 'P14']\n",
    "for table, name in zip(table_list,name_list):\n",
    "    table.to_csv(path + '/mass_sf1/table_{}.csv'.format(name))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "927a869e",
   "metadata": {},
   "source": [
    " II. Loading 2010 DHC data from Massachusetts\n",
    " a) Read in the segments of the 2010 SF1 for Massachusetts downloaded from [here](https://archive.ciser.cornell.edu/explore/download-centers/census-2010-sf1/files)\n",
    "\n",
    "a) The specific segments are selected based on the columns from on Abie and Os's work:\n",
    "* P1 - total population\n",
    "* P8 - race in 63 categories\n",
    "* P9 - race in 63 categories, non-hispanic\n",
    "* P10 - race in 63 categories for 18+\n",
    "* P11 - race in 63 categories, non-hispanic for 18+\n",
    "* P12 - sex by age\n",
    "* P14 - sex by for below 20 years of age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c0778a00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FILEID</th>\n",
       "      <th>STUSAB</th>\n",
       "      <th>SUMLEV</th>\n",
       "      <th>GEOVAR</th>\n",
       "      <th>GEOCOMP</th>\n",
       "      <th>CHARITER</th>\n",
       "      <th>CIFSN</th>\n",
       "      <th>LOGRECNO</th>\n",
       "      <th>GEOID</th>\n",
       "      <th>GEOCODE</th>\n",
       "      <th>...</th>\n",
       "      <th>NAME</th>\n",
       "      <th>FUNCSTAT</th>\n",
       "      <th>GCUNI</th>\n",
       "      <th>POP100</th>\n",
       "      <th>HU100</th>\n",
       "      <th>INTPTLAT</th>\n",
       "      <th>INTPTLON</th>\n",
       "      <th>LSADC</th>\n",
       "      <th>PARTFLAG</th>\n",
       "      <th>UGA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DHCST</td>\n",
       "      <td>MA</td>\n",
       "      <td>40</td>\n",
       "      <td>00</td>\n",
       "      <td>00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0400000US25</td>\n",
       "      <td>25</td>\n",
       "      <td>...</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>A</td>\n",
       "      <td>N</td>\n",
       "      <td>6547629</td>\n",
       "      <td>0</td>\n",
       "      <td>42.156520</td>\n",
       "      <td>-71.489592</td>\n",
       "      <td>00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DHCST</td>\n",
       "      <td>MA</td>\n",
       "      <td>40</td>\n",
       "      <td>00</td>\n",
       "      <td>01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0400001US25</td>\n",
       "      <td>25</td>\n",
       "      <td>...</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>A</td>\n",
       "      <td>N</td>\n",
       "      <td>6020932</td>\n",
       "      <td>0</td>\n",
       "      <td>42.223216</td>\n",
       "      <td>-71.313364</td>\n",
       "      <td>00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DHCST</td>\n",
       "      <td>MA</td>\n",
       "      <td>40</td>\n",
       "      <td>00</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0400043US25</td>\n",
       "      <td>25</td>\n",
       "      <td>...</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>A</td>\n",
       "      <td>N</td>\n",
       "      <td>526697</td>\n",
       "      <td>0</td>\n",
       "      <td>42.194810</td>\n",
       "      <td>-71.769011</td>\n",
       "      <td>00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DHCST</td>\n",
       "      <td>MA</td>\n",
       "      <td>40</td>\n",
       "      <td>00</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0400044US25</td>\n",
       "      <td>25</td>\n",
       "      <td>...</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>A</td>\n",
       "      <td>N</td>\n",
       "      <td>68532</td>\n",
       "      <td>0</td>\n",
       "      <td>42.163135</td>\n",
       "      <td>-71.498091</td>\n",
       "      <td>00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DHCST</td>\n",
       "      <td>MA</td>\n",
       "      <td>40</td>\n",
       "      <td>00</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0400048US25</td>\n",
       "      <td>25</td>\n",
       "      <td>...</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>A</td>\n",
       "      <td>N</td>\n",
       "      <td>458165</td>\n",
       "      <td>0</td>\n",
       "      <td>42.195537</td>\n",
       "      <td>-71.812951</td>\n",
       "      <td>00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 97 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  FILEID STUSAB  SUMLEV GEOVAR GEOCOMP  CHARITER  CIFSN  LOGRECNO  \\\n",
       "0  DHCST     MA      40     00      00         0      0         1   \n",
       "1  DHCST     MA      40     00      01         0      0         2   \n",
       "2  DHCST     MA      40     00      43         0      0         3   \n",
       "3  DHCST     MA      40     00      44         0      0         4   \n",
       "4  DHCST     MA      40     00      48         0      0         5   \n",
       "\n",
       "         GEOID GEOCODE  ...           NAME  FUNCSTAT  GCUNI   POP100  HU100  \\\n",
       "0  0400000US25      25  ...  Massachusetts         A      N  6547629      0   \n",
       "1  0400001US25      25  ...  Massachusetts         A      N  6020932      0   \n",
       "2  0400043US25      25  ...  Massachusetts         A      N   526697      0   \n",
       "3  0400044US25      25  ...  Massachusetts         A      N    68532      0   \n",
       "4  0400048US25      25  ...  Massachusetts         A      N   458165      0   \n",
       "\n",
       "    INTPTLAT   INTPTLON  LSADC PARTFLAG  UGA  \n",
       "0  42.156520 -71.489592     00      NaN  NaN  \n",
       "1  42.223216 -71.313364     00      NaN  NaN  \n",
       "2  42.194810 -71.769011     00      NaN  NaN  \n",
       "3  42.163135 -71.498091     00      NaN  NaN  \n",
       "4  42.195537 -71.812951     00      NaN  NaN  \n",
       "\n",
       "[5 rows x 97 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Demographic and Housing Characteristics File\n",
    "col_names = 'FILEID,STUSAB,SUMLEV,GEOVAR,GEOCOMP,CHARITER,CIFSN,LOGRECNO,GEOID,GEOCODE,REGION,DIVISION,STATE,STATENS,COUNTY,COUNTYCC,COUNTYNS,COUSUB,COUSUBCC,COUSUBNS,SUBMCD,SUBMCDCC,SUBMCDNS,ESTATEFP,ESTATECC,ESTATENS,CONCIT,CONCITCC,CONCITNS,PLACE,PLACECC,PLACENS,TRACT,BLKGRP,BLOCK,AIANHH,AIHHTLI,AIANHHFP,AIANHHCC,AIANHHNS,AITS,AITSFP,AITSCC,AITSNS,TTRACT,BTBG,ANRC,ANRCCC,ANRCNS,CBSA,MEMI,CSA,METDIV,NECTA,NMEMI,CNECTA,NECTADIV,CBSAPCI,NECTAPCI,UA,UATYPE,UR,CD111,CD113,CD114,CD115,CD116,SLDU11,SLDU12,SLDU14,SLDU16,SLDU18,SLDL11,SLDL12,SLDL14,SLDL16,SLDL18,VTD,VTDI,ZCTA,SDELM,SDSEC,SDUNI,PUMA,AREALAND,AREAWATR,BASENAME,NAME,FUNCSTAT,GCUNI,POP100,HU100,INTPTLAT,INTPTLON,LSADC,PARTFLAG,UGA'.split(',')\n",
    "mass_dhc = pd.read_csv(path + '/ma2010ur1_49segments_csv/ma2010.dhc /mageo2010.dhc',\n",
    "                     sep='|',\n",
    "                     header=None,\n",
    "                     names=col_names,\n",
    "                     low_memory=False,\n",
    "                     encoding='latin1')\n",
    "mass_dhc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58942622",
   "metadata": {},
   "outputs": [],
   "source": [
    "mass_dhc_1 = pd.read_csv(path + '/ma2010ur1_49segments_csv/ma2010.dhc /ma000012010.dhc',sep='|',header=None,low_memory=False)\n",
    "mass_dhc_2 = pd.read_csv(path + '/ma2010ur1_49segments_csv/ma2010.dhc /ma000022010.dhc',sep='|',header=None,low_memory=False)\n",
    "mass_dhc_4 = pd.read_csv(path + '/ma2010ur1_49segments_csv/ma2010.dhc /ma000042010.dhc',sep='|',header=None,low_memory=False)\n",
    "mass_dhc_5 = pd.read_csv(path + '/ma2010ur1_49segments_csv/ma2010.dhc /ma000052010.dhc',sep='|',header=None,low_memory=False)\n",
    "mass_dhc_6 = pd.read_csv(path + '/ma2010ur1_49segments_csv/ma2010.dhc /ma000062010.dhc',sep='|',header=None,low_memory=False)\n",
    "mass_dhc_7 = pd.read_csv(path + '/ma2010ur1_49segments_csv/ma2010.dhc /ma000072010.dhc',sep='|',header=None,low_memory=False)\n",
    "mass_dhc_8 = pd.read_csv(path + '/ma2010ur1_49segments_csv/ma2010.dhc /ma000082010.dhc',sep='|',header=None,low_memory=False)\n",
    "mass_dhc_9 = pd.read_csv(path + '/ma2010ur1_49segments_csv/ma2010.dhc /ma000092010.dhc',sep='|',header=None,low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b0a5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "mass_dhc_1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ebcb3b9",
   "metadata": {},
   "source": [
    "b) The DHC file segments doesn't come with column names so naming them below based on the technical documentation found [here](https://www2.census.gov/programs-surveys/decennial/2020/program-management/data-product-planning/2010-demonstration-data-products/02-Demographic_and_Housing_Characteristics/2022-03-16_Summary_File/2022-03-16_Technical%20Document/2022-03-16_Technical%20Document.pdf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9743c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the columns 1-6 for now to make it easier to count\n",
    "P1_P9=mass_dhc_1.iloc[:,6:] # P1-P9\n",
    "P1_P9.rename(columns={x:y for x,y in zip(P1_P9.columns,range(0,len(P1_P9.columns)))})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800688c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, let's isolate variables P1, P8, P9 into their own dfs\n",
    "cols_to_keep = mass_dhc_1[[0,1,4]] # col 0 - FILEID, col 1 - STATE, col 4 - LOGRECNO\n",
    "dhc_P1 = cols_to_keep.join(P1_P9.iloc[:, 0]) # Total Population\n",
    "dhc_P8 = cols_to_keep.join(P1_P9.iloc[:,(1+4+8+3+17+7+16):(1+4+8+3+17+7+15+72)])\n",
    "dhc_P9 = cols_to_keep.join(P1_P9.iloc[:,(1+4+8+3+17+7+15+71):])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd41c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check to make sure each df has the right number of cols:\n",
    "print(dhc_P1.shape) # P1 should have 3 + 1 = 4 cols\n",
    "print(dhc_P8.shape) # P8 should have 3 + 71 = 74 cols\n",
    "print(dhc_P9.shape) # P9 should have 3 + 73 = 76 cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf1ffff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, let's start renaming columns in each df, starting with P1\n",
    "dhc_P1.rename(columns={0:'FILEID', 1: 'STATE', 4: 'LOGRECNO',6:'P0010001'}, inplace=True)\n",
    "dhc_P1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a54a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a function to rename columns for the rest of the dfs\n",
    "def rename_cols(variable, length, df):\n",
    "    col_names = []\n",
    "    for i in range(1,length+1):\n",
    "        if variable < 10:\n",
    "            if i < 10:\n",
    "                col_names.append('P00{}00{}'.format(variable,i))\n",
    "            else: \n",
    "                col_names.append('P00{}0{}'.format(variable,i))\n",
    "        else:\n",
    "            if i < 10:\n",
    "                col_names.append('P0{}000{}'.format(variable,i))\n",
    "            else: \n",
    "                col_names.append('P0{}00{}'.format(variable,i))\n",
    "             \n",
    "    col_names = ['FILEID', 'STATE', 'LOGRECNO'] + col_names\n",
    "    \n",
    "    df.columns = col_names\n",
    "    \n",
    "    print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2332db",
   "metadata": {},
   "outputs": [],
   "source": [
    "rename_cols(8, 71, dhc_P8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec97d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "rename_cols(9, 73, dhc_P9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c07e25e8",
   "metadata": {},
   "source": [
    "c) Repeating the above steps to isolate variables P10, P11, P12, and P12A from mass_dhc_2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4596b85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mass_dhc_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a96b66e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "P10_P12A = mass_dhc_2.iloc[:,5:] # P10-P12A\n",
    "P10_P12A.rename(columns={x:y for x,y in zip(P10_P12A.columns,range(0,len(P10_P12A.columns)))})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e45efd65",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_keep = mass_dhc_2[[0,1,4]]\n",
    "dhc_P10 = cols_to_keep.join(P10_P12A.iloc[:, :71]) #first 71 cols\n",
    "dhc_P11 = cols_to_keep.join(P10_P12A.iloc[:, 71:(71+73)])\n",
    "dhc_P12 = cols_to_keep.join(P10_P12A.iloc[:, (71+73):(71+73+49)])\n",
    "dhc_P12A = cols_to_keep.join(P10_P12A.iloc[:, (71+73+49):(71+73+49+49)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb22815",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check to make sure we have the right number of columns\n",
    "print(dhc_P10.shape) # P10 should have 3 + 71 = 74 cols\n",
    "print(dhc_P11.shape) # ... 3 + 73 = 76\n",
    "print(dhc_P12.shape) # ... 3 + 49 = 52\n",
    "print(dhc_P12A.shape) # ... 3 + 49 = 52"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09da1aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "rename_cols(10,71,dhc_P10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5acd4eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "rename_cols(11, 73, dhc_P11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84660a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "rename_cols(12, 49, dhc_P12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ad505c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_lettered_cols(variable, length, df):\n",
    "    col_names = []\n",
    "    for i in range(1,length+1):\n",
    "        if i < 10:\n",
    "            col_names.append('P0{}00{}'.format(variable,i))\n",
    "        else: \n",
    "            col_names.append('P0{}0{}'.format(variable,i))\n",
    "    \n",
    "    col_names = ['FILEID', 'STATE', 'LOGRECNO'] + col_names\n",
    "    \n",
    "    df.columns = col_names\n",
    "    \n",
    "    print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f309bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "rename_lettered_cols('12A', 49, dhc_P12A)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c437a277",
   "metadata": {},
   "source": [
    "d) Repeating above steps to isolate 12B-12U from mass_dhc_4 - mass_dhc_8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba24695",
   "metadata": {},
   "outputs": [],
   "source": [
    "mass_dhc_4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97a858b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def isolate_variable(df, start, end):\n",
    "    cols_to_keep = df[[0,1,4]]\n",
    "    appended_df = df.iloc[:,5:]\n",
    "    appended_df.rename(columns={x:y for x,y in zip(appended_df.columns,range(0,len(appended_df.columns)))})\n",
    "    variable_df = cols_to_keep.join(appended_df.iloc[:,start:end])\n",
    "    print(variable_df.shape[1])\n",
    "    return variable_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb8bd6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All of these should have a length of 52\n",
    "dhc_P12B = isolate_variable(mass_dhc_4,0,49)\n",
    "dhc_P12C = isolate_variable(mass_dhc_4,49,(49+49))\n",
    "dhc_P12D = isolate_variable(mass_dhc_5,0,49)\n",
    "dhc_P12E = isolate_variable(mass_dhc_5,49,(49+49))\n",
    "dhc_P12F = isolate_variable(mass_dhc_5,(49+49),(49+49+49))\n",
    "dhc_P12G = isolate_variable(mass_dhc_5,(49+49+49),(49+49+49+49))\n",
    "dhc_P12H = isolate_variable(mass_dhc_5,(49+49+49+49),(49+49+49+49+49))\n",
    "dhc_P12I = isolate_variable(mass_dhc_6,0,49)\n",
    "dhc_P12K = isolate_variable(mass_dhc_6,49,(49+49))\n",
    "dhc_P12M = isolate_variable(mass_dhc_6,(49+49+49),(49+49+49+49))\n",
    "dhc_P12O = isolate_variable(mass_dhc_7,49,(49+49))\n",
    "dhc_P12Q = isolate_variable(mass_dhc_7,(49+49+49), (49+49+49+49))\n",
    "dhc_P12S = isolate_variable(mass_dhc_8,0,49)\n",
    "dhc_P12U = isolate_variable(mass_dhc_8,(49+49),(49+49+49))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9450d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "letters = ['B','C','D','E','F','G','H','I','K','M','O','Q','S','U']\n",
    "\n",
    "for letter in letters:\n",
    "    rename_lettered_cols('12{}'.format(letter), 49, globals()['dhc_P12{}'.format(letter)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b414c282",
   "metadata": {},
   "source": [
    "e) Lastly, isolatating P14 from mass_dhc_9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "befbd779",
   "metadata": {},
   "outputs": [],
   "source": [
    "dhc_P14 = isolate_variable(mass_dhc_9, 30,(30+43)) \n",
    "rename_cols(14,43,dhc_P14)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a903916",
   "metadata": {},
   "source": [
    "f) Finally saving tables to csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c86321b",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_list = [dhc_P1, dhc_P8, dhc_P9, dhc_P10, dhc_P11, dhc_P12, dhc_P12A, dhc_P12B, dhc_P12C, dhc_P12D, dhc_P12E, dhc_P12F, dhc_P12G, dhc_P12H, dhc_P12I, dhc_P12K, dhc_P12M, dhc_P12O, dhc_P12Q, dhc_P12S, dhc_P12U, dhc_P14]\n",
    "name_list = ['P1', 'P8', 'P9', 'P10', 'P11', 'P12', 'P12A', 'P12B', 'P12C', 'P12D', 'P12E', 'P12F', 'P12G', 'P12H', 'P12I', 'P12K', 'P12M', 'P12O', 'P12Q', 'P12S', 'P12U','P14']\n",
    "for table, name in zip(table_list,name_list):\n",
    "    table.to_csv(path + '/mass_dhc/table_{}.csv'.format(name))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
